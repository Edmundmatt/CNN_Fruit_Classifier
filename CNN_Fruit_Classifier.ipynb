{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQvui7PKwN5l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdztp9L0Kr03"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    \"\"\" Plot the history of accuracies\"\"\"\n",
        "    accuracies = [x['test_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "    \n",
        "\n",
        "def plot_losses(history):\n",
        "    \"\"\" Plot the losses in each epoch\"\"\"\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['test_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njNo2eP24GxV"
      },
      "source": [
        "# Training class\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eu8bQbfwZh_"
      },
      "source": [
        "# CNN model\n",
        "\n",
        "class FruitClassification(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            torch.nn.Dropout(0,25),\n",
        "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1440000,32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16,8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8,3)\n",
        "        )\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KysDC3v63MEj"
      },
      "source": [
        "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
        "    train_loss,train_correct=0.0,0\n",
        "    model.train()\n",
        "    for images, labels in dataloader:\n",
        "\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = loss_fn(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        scores, predictions = torch.max(output.data, 1)\n",
        "        train_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    return train_loss,train_correct\n",
        "  \n",
        "def valid_epoch(model,device,dataloader,loss_fn):\n",
        "    valid_loss, val_correct = 0.0, 0\n",
        "    model.eval()\n",
        "    for images, labels in dataloader:\n",
        "\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        output = model(images)\n",
        "        loss=loss_fn(output,labels)\n",
        "        valid_loss+=loss.item()*images.size(0)\n",
        "        scores, predictions = torch.max(output.data,1)\n",
        "        val_correct+=(predictions == labels).sum().item()\n",
        "\n",
        "    return valid_loss,val_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg_LBVkQwm0r"
      },
      "source": [
        "# Import training images from zipped folder in Colab directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip /content/traindata_postselection.zip\n",
        "\n",
        "notebook_path = os.path.abspath(\"COMP309FinalProject.ipynb\")\n",
        "data_dir = os.path.join(os.path.dirname(notebook_path), \"traindata_postselection\")\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir,transform = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize(0.5, 0.5, 0.5)\n",
        "]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yLTVOl6wnbw"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# dataset = ConcatDataset([train_data, test_dataset])\n",
        "\n",
        "num_epochs=15\n",
        "batch_size=30\n",
        "k=10\n",
        "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
        "foldperf={}\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmuzLH183f5p"
      },
      "source": [
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = FruitClassification()\n",
        "    model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
        "\n",
        "    history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n",
        "        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "        test_acc = test_correct / len(test_loader.sampler) * 100\n",
        "\n",
        "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n",
        "                                                                                                             num_epochs,\n",
        "                                                                                                             train_loss,\n",
        "                                                                                                             test_loss,\n",
        "                                                                                                             train_acc,\n",
        "                                                                                                             test_acc))\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['test_acc'].append(test_acc)\n",
        "\n",
        "    foldperf['fold{}'.format(fold+1)] = history  \n",
        "\n",
        "# torch.save(model,'k_cross_CNN.pt')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxt-P0zN8oHh"
      },
      "source": [
        "testl_f,tl_f,testa_f,ta_f=[],[],[],[]\n",
        "k=10\n",
        "for f in range(1,k+1):\n",
        "\n",
        "     tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n",
        "     testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n",
        "\n",
        "     ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n",
        "     testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n",
        "\n",
        "print('Performance of {} fold cross validation'.format(k))\n",
        "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc: {:.2f}\"\n",
        ".format(np.mean(tl_f),np.mean(testl_f),np.mean(ta_f),np.mean(testa_f)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4wG0QZzK1l2"
      },
      "source": [
        "plot_accuracies(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7HiRFD4Y2Tm"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}